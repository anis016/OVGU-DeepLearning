{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tf.set_random_seed(42)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)  # for logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data():\n",
    "\n",
    "    dirname, _ = os.path.split(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "    data_dir = os.path.join(dirname, \"data\")\n",
    "    MNIST_dir = os.path.join(data_dir, \"MNIST\")\n",
    "\n",
    "    if os.path.exists(MNIST_dir):\n",
    "        all_files = glob.glob(MNIST_dir + \"/*.csv\")\n",
    "        train_path = all_files[0] if 'train' in all_files[0] else all_files[1]\n",
    "        test_path  = all_files[0] if 'test' in all_files[0] else all_files[1]\n",
    "\n",
    "        train = pd.read_csv(train_path, header=None)\n",
    "        X_train = train.iloc[:,1:].values/255.0\n",
    "        y_train = train.iloc[:,0].values\n",
    "\n",
    "        test = pd.read_csv(test_path, header=None)\n",
    "        X_test = test.iloc[:, 1:].values/255.0\n",
    "        y_test = test.iloc[:, 0].values\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    else:\n",
    "        raise IOError(\"Path: {0} not found!\".format(MNIST_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the normalized MNIST data\n",
    "X_train, y_train, X_test, y_test = get_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input function for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": np.array(X_train)},\n",
    "    y = np.array(y_train),\n",
    "    num_epochs=None,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ghostrig/Python_Workspace/deep-learning/deepl_venv/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ghostrig/Python_Workspace/deep-learning/deepl_venv/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'x': <tf.Tensor 'random_shuffle_queue_DequeueMany:1' shape=(128, 784) dtype=float64>},\n",
       " <tf.Tensor 'random_shuffle_queue_DequeueMany:2' shape=(128,) dtype=int64>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input function for Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": np.array(X_test)},\n",
    "    y = np.array(y_test),\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(inputs, reuse, is_training=False):\n",
    "    with tf.variable_scope(\"DNN_NET\", reuse=reuse):\n",
    "        x = inputs[\"x\"]\n",
    "        fc1 = tf.layers.dense(x, units=512, activation=tf.nn.relu)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=0.4, training=is_training)\n",
    "        fc2 = tf.layers.dense(fc1, units=256, activation=tf.nn.relu)\n",
    "        fc2 = tf.layers.dropout(fc2, rate=0.4, training=is_training)\n",
    "        fc3 = tf.layers.dense(fc2, units=128, activation=tf.nn.relu)\n",
    "        fc3 = tf.layers.dropout(fc3, rate=0.4, training=is_training)\n",
    "        out = tf.layers.dense(fc3, units=10)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(inputs, reuse, is_training=False):\n",
    "    with tf.variable_scope(\"Conv_NET\", reuse=reuse):\n",
    "        ## Input layer\n",
    "        # MNIST data input is a 1-D vector of 784 features.\n",
    "        # Reshape each example to match the format: [batch_size X img_height X img_width X channel]\n",
    "\n",
    "        input_layer = tf.reshape(inputs[\"x\"], shape=[-1, 28, 28, 1])\n",
    "        \n",
    "        ## Convolutional Layer and Pooling Layer#1\n",
    "        # Convolution layer with 32 filters with kernel size [5 X 5] with ReLU activation function.\n",
    "        conv_layer1 = tf.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "        conv1 = conv_layer1.apply(inputs=input_layer)\n",
    "        # Max pooling with filter size [2 X 2] and stride of 2 (specifies pooled region do not overlap)\n",
    "        pool1 = tf.layers.max_pooling2d(\n",
    "            inputs=conv1,\n",
    "            pool_size=[2, 2],\n",
    "            strides=2\n",
    "        )\n",
    "        \n",
    "        ## Convolutional Layer and Pooling Layer#2\n",
    "        # Convolution layer with 64 filters with kernel size [5 X 5] with ReLU activation function.\n",
    "        conv_layer2 = tf.layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "        conv2 = conv_layer2.apply(inputs=pool1)\n",
    "        # Max pooling with filter size [2 X 2] and stride of 2 (specifies pooled region do not overlap)\n",
    "        pool2 = tf.layers.max_pooling2d(\n",
    "            inputs=conv2,\n",
    "            pool_size=[2, 2],\n",
    "            strides=2\n",
    "        )\n",
    "            \n",
    "        # Flatten the data to a 1-D vector for the Dense layer\n",
    "        fc = tf.layers.flatten(pool2)\n",
    "\n",
    "        # Dense Layer\n",
    "        dense = tf.layers.dense(inputs=fc, units=1024, activation=tf.nn.relu)\n",
    "        dense = tf.layers.dropout(inputs=dense, rate=0.25, training=is_training)\n",
    "\n",
    "        # Output Layer for MNIST 10 class prediction\n",
    "        out = tf.layers.dense(inputs=dense, units=10)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_funct(features, labels, mode, params):\n",
    "    # logits = dnn_model(features, is_training=True, reuse=False)\n",
    "    # logits_ = dnn_model(features, reuse=True)\n",
    "    \n",
    "    logits  = cnn_model(features, is_training=True, reuse=False)\n",
    "    logits_ = cnn_model(features, reuse=True)\n",
    "    \n",
    "    # predictions\n",
    "    prediction = tf.nn.softmax(logits_)\n",
    "    prediction_classes = tf.argmax(prediction, axis=1)\n",
    "    \n",
    "    # prediction mode\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, \n",
    "                                          predictions={'class_ids': prediction_classes[:, tf.newaxis],\n",
    "                                                       'prediction': prediction_classes})\n",
    "    \n",
    "    # define the loss function to be optimized by \n",
    "    # 1) first calculating the cross-entropy between theoutput of the neural network and \n",
    "    #    the true labels for the input data.\n",
    "    # 2) then reduce the cross-entropy batch-tensor to a single number which can be used \n",
    "    #    in the optimization of the neural network\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                                   labels=tf.cast(labels, tf.int32))\n",
    "    loss_op = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    # define the optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "    # define train_op\n",
    "    train_op = optimizer.minimize(loss_op,\n",
    "                                  global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=prediction_classes)\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss_op,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops={\"accuracy\": acc_op}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate  = 0.01\n",
    "params = {\"learning_rate\": learning_rate}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the estimator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../saved_models/cnn_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7facddb7a630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_funct, model_dir='../saved_models/cnn_estimator', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/ghostrig/Python_Workspace/deep-learning/deepl_venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:808: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../saved_models/cnn_estimator/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.300946104565414, step = 0\n",
      "INFO:tensorflow:global_step/sec: 19.9512\n",
      "INFO:tensorflow:loss = 0.36960930523457775, step = 100 (5.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0332\n",
      "INFO:tensorflow:loss = 0.13408775591333177, step = 200 (4.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5119\n",
      "INFO:tensorflow:loss = 0.1678062379687591, step = 300 (5.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8572\n",
      "INFO:tensorflow:loss = 0.05321218592226389, step = 400 (5.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.28\n",
      "INFO:tensorflow:loss = 0.11755592058104525, step = 500 (4.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3959\n",
      "INFO:tensorflow:loss = 0.07273105534061533, step = 600 (4.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3779\n",
      "INFO:tensorflow:loss = 0.13853808903371853, step = 700 (4.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3959\n",
      "INFO:tensorflow:loss = 0.18949839260287585, step = 800 (4.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3167\n",
      "INFO:tensorflow:loss = 0.013348935379882737, step = 900 (4.922 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ../saved_models/cnn_estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.11361727018878788.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7facddb66cc0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-06-22:00:53\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../saved_models/cnn_estimator/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-06-22:00:55\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9681, global_step = 1000, loss = 0.11676158\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ../saved_models/cnn_estimator/model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9681, 'loss': 0.11676158, 'global_step': 1000}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 96.81%\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification accuracy: {0:.2%}\".format(result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_images = X_test[0:9]\n",
    "expected = y_test[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": some_images},\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../saved_models/cnn_estimator/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "cls_pred = list(predictions)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([4]),\n",
       " array([1]),\n",
       " array([4]),\n",
       " array([9]),\n",
       " array([5])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cls_pred[i]['class_ids'] for i in range(len(cls_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction is \"7\", expected \"7\"\n",
      "\n",
      "Prediction is \"2\", expected \"2\"\n",
      "\n",
      "Prediction is \"1\", expected \"1\"\n",
      "\n",
      "Prediction is \"0\", expected \"0\"\n",
      "\n",
      "Prediction is \"4\", expected \"4\"\n",
      "\n",
      "Prediction is \"1\", expected \"1\"\n",
      "\n",
      "Prediction is \"4\", expected \"4\"\n",
      "\n",
      "Prediction is \"9\", expected \"9\"\n",
      "\n",
      "Prediction is \"5\", expected \"5\"\n"
     ]
    }
   ],
   "source": [
    "template = ('\\nPrediction is \"{}\", expected \"{}\"')\n",
    "\n",
    "for pred_dict, expec in zip(cls_pred, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    print(template.format(class_id, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dl-numpy",
   "language": "python",
   "name": "deepl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
