{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tf.set_random_seed(42)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)  # for logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data():\n",
    "\n",
    "    dirname, _ = os.path.split(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "    data_dir = os.path.join(dirname, \"data\")\n",
    "    MNIST_dir = os.path.join(data_dir, \"MNIST\")\n",
    "\n",
    "    if os.path.exists(MNIST_dir):\n",
    "        all_files = glob.glob(MNIST_dir + \"/*.csv\")\n",
    "        train_path = all_files[0] if 'train' in all_files[0] else all_files[1]\n",
    "        test_path  = all_files[0] if 'test' in all_files[0] else all_files[1]\n",
    "\n",
    "        train = pd.read_csv(train_path, header=None)\n",
    "        X_train = train.iloc[:,1:].values/255.0\n",
    "        y_train = train.iloc[:,0].values\n",
    "\n",
    "        test = pd.read_csv(test_path, header=None)\n",
    "        X_test = test.iloc[:, 1:].values/255.0\n",
    "        y_test = test.iloc[:, 0].values\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    else:\n",
    "        raise IOError(\"Path: {0} not found!\".format(MNIST_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the normalized MNIST data\n",
    "X_train, y_train, X_test, y_test = get_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input function for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": np.array(X_train)},\n",
    "    y = np.array(y_train),\n",
    "    num_epochs=None,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ghostrig/Python_Workspace/deep-learning/deepl_venv/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ghostrig/Python_Workspace/deep-learning/deepl_venv/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'x': <tf.Tensor 'random_shuffle_queue_DequeueMany:1' shape=(128, 784) dtype=float64>},\n",
       " <tf.Tensor 'random_shuffle_queue_DequeueMany:2' shape=(128,) dtype=int64>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input function for Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": np.array(X_test)},\n",
    "    y = np.array(y_test),\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(inputs, reuse, is_training=False):\n",
    "    with tf.variable_scope(\"DNN_NET\", reuse=reuse):\n",
    "        x = inputs[\"x\"]\n",
    "        fc1 = tf.layers.dense(x, units=512, activation=tf.nn.relu)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=0.4, training=is_training)\n",
    "        fc2 = tf.layers.dense(fc1, units=256, activation=tf.nn.relu)\n",
    "        fc2 = tf.layers.dropout(fc2, rate=0.4, training=is_training)\n",
    "        fc3 = tf.layers.dense(fc2, units=128, activation=tf.nn.relu)\n",
    "        fc3 = tf.layers.dropout(fc3, rate=0.4, training=is_training)\n",
    "        out = tf.layers.dense(fc3, units=10)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(inputs, reuse, is_training=False):\n",
    "    with tf.variable_scope(\"Conv_NET\", reuse=reuse):\n",
    "        ## Input layer\n",
    "        # MNIST data input is a 1-D vector of 784 features.\n",
    "        # Reshape each example to match the format: [batch_size X img_height X img_width X channel]\n",
    "\n",
    "        input_layer = tf.reshape(inputs[\"x\"], shape=[-1, 28, 28, 1])\n",
    "        \n",
    "        ## Convolutional Layer and Pooling Layer#1\n",
    "        # Convolution layer with 32 filters with kernel size [5 X 5] with ReLU activation function.\n",
    "        conv_layer1 = tf.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "        conv1 = conv_layer1.apply(inputs=input_layer)\n",
    "        # Max pooling with filter size [2 X 2] and stride of 2 (specifies pooled region do not overlap)\n",
    "        pool1 = tf.layers.max_pooling2d(\n",
    "            inputs=conv1,\n",
    "            pool_size=[2, 2],\n",
    "            strides=2\n",
    "        )\n",
    "        \n",
    "        ## Convolutional Layer and Pooling Layer#2\n",
    "        # Convolution layer with 64 filters with kernel size [5 X 5] with ReLU activation function.\n",
    "        conv_layer2 = tf.layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "        conv2 = conv_layer2.apply(inputs=pool1)\n",
    "        # Max pooling with filter size [2 X 2] and stride of 2 (specifies pooled region do not overlap)\n",
    "        pool2 = tf.layers.max_pooling2d(\n",
    "            inputs=conv2,\n",
    "            pool_size=[2, 2],\n",
    "            strides=2\n",
    "        )\n",
    "            \n",
    "        # Flatten the data to a 1-D vector for the Dense layer\n",
    "        fc = tf.layers.flatten(pool2)\n",
    "\n",
    "        # Dense Layer\n",
    "        dense = tf.layers.dense(inputs=fc, units=1024, activation=tf.nn.relu)\n",
    "        dense = tf.layers.dropout(inputs=dense, rate=0.25, training=is_training)\n",
    "\n",
    "        # Output Layer for MNIST 10 class prediction\n",
    "        out = tf.layers.dense(inputs=dense, units=10)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_funct(features, labels, mode, params):\n",
    "    # logits = dnn_model(features, is_training=True, reuse=False)\n",
    "    # logits_ = dnn_model(features, reuse=True)\n",
    "    \n",
    "    logits  = cnn_model(features, is_training=True, reuse=False)\n",
    "    logits_ = cnn_model(features, reuse=True)\n",
    "    \n",
    "    # predictions\n",
    "    prediction = tf.nn.softmax(logits_)\n",
    "    prediction_classes = tf.argmax(prediction, axis=1)\n",
    "    \n",
    "    # prediction mode\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, \n",
    "                                          predictions={'class_ids': prediction_classes[:, tf.newaxis],\n",
    "                                                       'prediction': prediction_classes})\n",
    "    \n",
    "    # define the loss function to be optimized by \n",
    "    # 1) first calculating the cross-entropy between theoutput of the neural network and \n",
    "    #    the true labels for the input data.\n",
    "    # 2) then reduce the cross-entropy batch-tensor to a single number which can be used \n",
    "    #    in the optimization of the neural network\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                                   labels=tf.cast(labels, tf.int32))\n",
    "    loss_op = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    # define the optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "    # define train_op\n",
    "    train_op = optimizer.minimize(loss_op,\n",
    "                                  global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=prediction_classes)\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss_op,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops={\"accuracy\": acc_op}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate  = 0.01\n",
    "params = {\"learning_rate\": learning_rate}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the estimator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../saved_models/cnn_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4a75b6d9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_funct, model_dir='../saved_models/cnn_estimator', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../saved_models/cnn_estimator/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../saved_models/cnn_estimator/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.31209811496876, step = 0\n",
      "INFO:tensorflow:global_step/sec: 20.0689\n",
      "INFO:tensorflow:loss = 0.09515441882038242, step = 100 (4.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7995\n",
      "INFO:tensorflow:loss = 0.09260443545476586, step = 200 (5.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1331\n",
      "INFO:tensorflow:loss = 0.24140160856187484, step = 300 (4.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2791\n",
      "INFO:tensorflow:loss = 0.12383507908875759, step = 400 (4.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0919\n",
      "INFO:tensorflow:loss = 0.03839802769472121, step = 500 (4.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9692\n",
      "INFO:tensorflow:loss = 0.17792572888148947, step = 600 (5.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0057\n",
      "INFO:tensorflow:loss = 0.08580106263123048, step = 700 (4.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0443\n",
      "INFO:tensorflow:loss = 0.16236425512186983, step = 800 (4.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7063\n",
      "INFO:tensorflow:loss = 0.07510846211714961, step = 900 (5.074 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ../saved_models/cnn_estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.038972202545145496.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f4a75b6d1d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-06-21:30:48\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../saved_models/cnn_estimator/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-06-21:30:49\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.981, global_step = 1000, loss = 0.071738005\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ../saved_models/cnn_estimator/model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.981, 'loss': 0.071738005, 'global_step': 1000}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 98.10%\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification accuracy: {0:.2%}\".format(result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_images = X_test[0:9]\n",
    "expected = y_test[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": some_images},\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../saved_models/cnn_estimator/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "cls_pred = list(predictions)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([4]),\n",
       " array([1]),\n",
       " array([4]),\n",
       " array([9]),\n",
       " array([5])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cls_pred[i]['class_ids'] for i in range(len(cls_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction is \"7\", expected \"7\"\n",
      "\n",
      "Prediction is \"2\", expected \"2\"\n",
      "\n",
      "Prediction is \"1\", expected \"1\"\n",
      "\n",
      "Prediction is \"0\", expected \"0\"\n",
      "\n",
      "Prediction is \"4\", expected \"4\"\n",
      "\n",
      "Prediction is \"1\", expected \"1\"\n",
      "\n",
      "Prediction is \"4\", expected \"4\"\n",
      "\n",
      "Prediction is \"9\", expected \"9\"\n",
      "\n",
      "Prediction is \"5\", expected \"5\"\n"
     ]
    }
   ],
   "source": [
    "template = ('\\nPrediction is \"{}\", expected \"{}\"')\n",
    "\n",
    "for pred_dict, expec in zip(cls_pred, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    print(template.format(class_id, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dl-numpy",
   "language": "python",
   "name": "deepl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
